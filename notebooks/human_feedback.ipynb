{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bound-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from compas import Compas\n",
    "import torch\n",
    "from Models import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "historical-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Compas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "racial-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_df = pd.read_csv('human_feedback.csv')\n",
    "instances_df = pd.read_csv('instances_with_id.csv', header=None)\n",
    "cfs_np = cfs_df.to_numpy()\n",
    "instances_np = instances_df.to_numpy()\n",
    "cfs_torch = d.df_to_torch(cfs_df.iloc[:, 2:-2])\n",
    "instances_torch = instances_df.iloc[:, 1:-1].copy()\n",
    "instances_torch.columns = d.column_names\n",
    "instances_torch = d.df_to_torch(instances_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "scientific-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pairs = 1305\n",
    "n_columns = d.data_torch_train.shape[1]\n",
    "\n",
    "pairs = torch.zeros(n_pairs, n_columns)\n",
    "targets = torch.zeros(n_pairs)\n",
    "\n",
    "counter = 0\n",
    "nr = 0\n",
    "\n",
    "for i in range(len(instances_np)-1):\n",
    "    i_id = instances_np[i][0]\n",
    "    i_torch = instances_torch[i]\n",
    "    for cf in range(5):\n",
    "        \n",
    "        if cfs_np[counter][0] != i_id:\n",
    "            print('Something goes wrong')\n",
    "        \n",
    "        if cfs_np[counter][-1] != 'None':\n",
    "            \n",
    "            cf_torch = cfs_torch[counter]\n",
    "            difference = cf_torch - i_torch\n",
    "            \n",
    "            pairs[nr] = difference\n",
    "            \n",
    "            if cfs_np[counter][-1] == 'True':\n",
    "                targets[nr] = 0\n",
    "            else:\n",
    "                targets[nr] = 1\n",
    "                \n",
    "            nr += 1\n",
    "                \n",
    "    \n",
    "            \n",
    "        counter +=1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-ethnic",
   "metadata": {},
   "source": [
    "## 0 means fair and 1 means unfair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "greatest-power",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3655)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(targets)/len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "lonely-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = round(0.75 * n_pairs)\n",
    "x_train = pairs[:split].detach()\n",
    "x_test = pairs[split:].detach()\n",
    "y_train = targets[:split].detach()\n",
    "y_test = targets[split:].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "numerous-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss before training 0.688576877117157\n",
      "Epoch: 0 -- train loss: 0.689 -- accuracy (test set): 0.58\n",
      "Epoch: 100 -- train loss: 0.589 -- accuracy (test set): 0.678\n",
      "Epoch: 200 -- train loss: 0.541 -- accuracy (test set): 0.69\n",
      "Epoch: 300 -- train loss: 0.516 -- accuracy (test set): 0.687\n",
      "Epoch: 400 -- train loss: 0.494 -- accuracy (test set): 0.681\n",
      "Test loss after Training 0.520545482635498\n",
      "The accuracy scrore on the test set: 0.681\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(x_train[0])\n",
    "hidden_dim = 100\n",
    "\n",
    "mlp_model = MLP(input_dim, hidden_dim)\n",
    "criterion = torch.nn.BCELoss() # BCE = binary cross entropy - our targets are binary \n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr = 0.001)\n",
    "\n",
    "### EVAL ###\n",
    "mlp_model.eval() # here sets the PyTorch module to evaluation mode. \n",
    "y_train_hat = mlp_model(x_train)\n",
    "before_train = criterion(y_train_hat.squeeze(), y_train)\n",
    "print('Test loss before training' , before_train.item())\n",
    "\n",
    "### TRAIN ###\n",
    "mlp_model.train() # here sets the PyTorch module to train mode. \n",
    "tot_epoch = 401\n",
    "for epoch in range(tot_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_train_hat = mlp_model(x_train)\n",
    "    # Compute Loss\n",
    "    loss = criterion(y_train_hat.squeeze(), y_train)\n",
    "    \n",
    "    if epoch%100==0:\n",
    "        y_test_hat = mlp_model(x_test)\n",
    "        print('Epoch: {} -- train loss: {} -- accuracy (test set): {}'.format(epoch, round(loss.item(), 3), mlp_model.accuracy(y_test_hat, y_test)))\n",
    "        y_test_hat = mlp_model(x_test)\n",
    "        \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "### EVAL ###\n",
    "mlp_model.eval()\n",
    "y_test_hat = mlp_model(x_test)\n",
    "after_train = criterion(y_test_hat.squeeze(), y_test) \n",
    "print('Test loss after Training' , after_train.item())\n",
    "\n",
    "print('The accuracy scrore on the test set:', mlp_model.accuracy(y_test_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "personalized-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp_model, \"f_fair_compas_human.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
