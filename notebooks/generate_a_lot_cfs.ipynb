{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alone-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Income import Income\n",
    "from compass import Compass\n",
    "from Dice import Dice\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "terminal-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24420])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Income import Income\n",
    "d = Income()\n",
    "d.target_torch_train.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-wisdom",
   "metadata": {},
   "source": [
    "## Load model, data structure and the cf generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assured-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = torch.load(\"classifier_model.pt\")\n",
    "m = torch.load(\"classifier_model_compass.pt\")\n",
    "m.eval()\n",
    "\n",
    "# d = Income()\n",
    "d = Compass()\n",
    "exp = Dice(d, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-activation",
   "metadata": {},
   "source": [
    "## Generate 5 cf's for every instance in the train set - INCOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instances = len(d.data_torch_train)\n",
    "n_cfs = 5\n",
    "cfs = torch.zeros((d.data_torch_train.shape[0], n_cfs, d.data_torch_train.shape[1]))\n",
    "\n",
    "for n_instance in np.arange(n_instances):\n",
    "    clear_output(wait=True)\n",
    "    print('instance ' + str(n_instance+1) + '/' + str(n_instances))\n",
    "    print('percentage: ' + str(round(n_instance*100/n_instances, 2)) + '%')\n",
    "    x = d.data_torch_train[n_instance]\n",
    "    cfs[n_instance] = exp.generate_cfs(x, total_cfs=n_cfs)\n",
    "    if n_instance % 100 == 0:\n",
    "        torch.save(cfs, 'cfs.pt')\n",
    "\n",
    "torch.save(cfs, 'cfs.pt')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-console",
   "metadata": {},
   "source": [
    "## Generate 5 cf's for every instance in the train set - COMPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "liable-woman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance 1482/5410\n",
      "percentage: 27.38%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0526e7ff26b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_torch_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_instance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_cfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_cfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'df'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sorry'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/artificial_intelligence/thesis/learning_to_be_fair/fresh_start/Dice.py\u001b[0m in \u001b[0;36mgenerate_cfs\u001b[0;34m(self, x, total_cfs, lr, max_iterations, distance_weight, diversity_weight, reg_weight, output, print_progress, f_fair)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_fair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis2/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis2/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_instances = len(d.data_torch_train)\n",
    "n_cfs = 5\n",
    "instances = np.zeros((n_instances, 6)).astype(object)\n",
    "cfs = np.zeros((n_instances*n_cfs, 6)).astype(object)\n",
    "    \n",
    "for n_instance in np.arange(n_instances):\n",
    "    clear_output(wait=True)\n",
    "    print('instance ' + str(n_instance+1) + '/' + str(n_instances))\n",
    "    print('percentage: ' + str(round(n_instance*100/n_instances, 2)) + '%')\n",
    "    \n",
    "    x = d.data_torch_train[n_instance]\n",
    "    output = exp.generate_cfs(x, total_cfs=n_cfs, output='df', diversity_weight=50)\n",
    "    if output == 'sorry':\n",
    "        continue\n",
    "    \n",
    "    cfs_i = output[0]\n",
    "    cfs_i['age'] = cfs_i['age'].astype('float').round().astype('int')\n",
    "    cfs_i['priors_count'] = cfs_i['priors_count'].astype('float').round().astype('int')\n",
    "    cfs_i['recidivism'] = cfs_i['recidivism'].astype('bool')\n",
    "    cfs_i = cfs_i.to_numpy()\n",
    "    cfs[n_instance*5:n_instance*5+5,:] = cfs_i\n",
    "    \n",
    "    x_df = d.data_df_train.iloc[n_instance].copy()\n",
    "    target = round(m(x).item())\n",
    "    x_df['recidivism'] = bool(target)\n",
    "    instances[n_instance] = x_df.to_numpy()\n",
    "    \n",
    "    if n_instance % 10 == 0:\n",
    "        cfs_df = pd.DataFrame(cfs[0:n_instance*5+5,:])\n",
    "        instances_df = pd.DataFrame(instances[0:n_instance+1,:])\n",
    "        \n",
    "        cfs_df.to_csv('cfs.csv', index=False, header=False)\n",
    "        instances_df.to_csv('instances.csv', index=False, header=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-product",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfs[0:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caring-procurement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Felony', 'African-American', 'Male', 34, 6, True],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-browse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
