{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_scrips.data import Income\n",
    "from python_scrips.data import Compas\n",
    "from python_scrips.data import Import\n",
    "from python_scrips.dice import Dice\n",
    "from python_scrips.models import MLP\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load classifier, create data instance and dice instance \n",
    "#### See 'classifier_training.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-704abfe21ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trained_models/classifier_income_originaldataset.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIncome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis2/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    582\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis2/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Models'"
     ]
    }
   ],
   "source": [
    "m = torch.load(\"trained_models/classifier_income_originaldataset.pt\")\n",
    "m.eval()\n",
    "\n",
    "d = Income()\n",
    "exp = Dice(d, m)\n",
    "x = d.data_torch_test[4]\n",
    "x_df = d.data_df_test.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of an instance x and 5 counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = exp.generate_cfs(x, distance_weight=0.5, diversity_weight=3, reg_weight=0.1, total_cfs=5, output='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs[0]['age'] = cfs[0]['age'].astype('float').round().astype('int')\n",
    "cfs[0]['priors_count'] = cfs[0]['priors_count'].astype('float').round().astype('int')\n",
    "cfs[0]['recidivism'] = cfs[0]['recidivism'].astype('bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a lot of counterfactuals & create 'pairs'\n",
    "#### See 'generate_a_lot_of_cfs.ipynb' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = torch.load('cfs.pt')\n",
    "x = d.data_torch_train\n",
    "n_pairs = 9000*5\n",
    "\n",
    "pairs = torch.zeros(n_pairs, exp.n_columns) # a pair is the difference between an instance x and its counterfactional cf\n",
    "targets = torch.zeros(n_pairs) # a pair is either fair or unfair\n",
    "pair_number = 0\n",
    "for i in range(d.len_train):\n",
    "    if i == 9000:\n",
    "        break\n",
    "    \n",
    "    cfs[i] = d.arg_max(cfs[i])\n",
    "    df = d.torch_to_df(cfs[i])\n",
    "    \n",
    "    for n_cf, cf in enumerate(cfs[i]):\n",
    "        # create pairs\n",
    "        difference = cf - x[i]\n",
    "        pairs[pair_number] = difference\n",
    "        \n",
    "        # check (un)fairness\n",
    "        if df['gender'][n_cf] == d.data_df_train['gender'][i] and df['race'][n_cf] == d.data_df_train['race'][i]:\n",
    "            targets[pair_number] = 0\n",
    "        else:\n",
    "            targets[pair_number] = 1\n",
    "        \n",
    "        pair_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train fair netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = round(0.75 * n_pairs)\n",
    "# x_train = pairs[:split].detach()\n",
    "# x_test = pairs[split:].detach()\n",
    "# y_train = targets[:split].detach()\n",
    "# y_test = targets[split:].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim = len(x_train[0])\n",
    "# hidden_dim = 100\n",
    "\n",
    "# mlp_model = MLP(input_dim, hidden_dim)\n",
    "# criterion = torch.nn.BCELoss() # BCE = binary cross entropy - our targets are binary \n",
    "# optimizer = torch.optim.Adam(mlp_model.parameters(), lr = 0.001)\n",
    "\n",
    "# ### EVAL ###\n",
    "# mlp_model.eval() # here sets the PyTorch module to evaluation mode. \n",
    "# y_train_hat = mlp_model(x_train)\n",
    "# before_train = criterion(y_train_hat.squeeze(), y_train)\n",
    "# print('Test loss before training' , before_train.item())\n",
    "\n",
    "# ### TRAIN ###\n",
    "# mlp_model.train() # here sets the PyTorch module to train mode. \n",
    "# tot_epoch = 401\n",
    "# for epoch in range(tot_epoch):\n",
    "#     optimizer.zero_grad()\n",
    "#     # Forward pass\n",
    "#     y_train_hat = mlp_model(x_train)\n",
    "#     # Compute Loss\n",
    "#     loss = criterion(y_train_hat.squeeze(), y_train)\n",
    "    \n",
    "#     if epoch%100==0:\n",
    "#         y_test_hat = mlp_model(x_test)\n",
    "#         print('Epoch: {} -- train loss: {} -- accuracy (test set): {}'.format(epoch, round(loss.item(), 3), mlp_model.accuracy(y_test_hat, y_test)))\n",
    "#         y_test_hat = mlp_model(x_test)\n",
    "        \n",
    "#     # Backward pass\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# ### EVAL ###\n",
    "# mlp_model.eval()\n",
    "# y_test_hat = mlp_model(x_test)\n",
    "# after_train = criterion(y_test_hat.squeeze(), y_test) \n",
    "# print('Test loss after Training' , after_train.item())\n",
    "\n",
    "# print('The accuracy scrore on the test set:', mlp_model.accuracy(y_test_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(mlp_model, \"f_fair.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find extra datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_fair = torch.load(\"f_fair_income.pt\")\n",
    "x = d.data_torch_test[2]\n",
    "cfs = exp.generate_cfs(x, f_fair=f_fair, total_cfs=3, distance_weight=0.5, diversity_weight=5, reg_weight=0.1, output='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = d.data_torch_train[0]\n",
    "\n",
    "cfs = exp.generate_cfs(instance, f_fair=f_fair, total_cfs=3, output='df')\n",
    "    \n",
    "random_int = random.randint(0, 2)\n",
    "\n",
    "augmented = cfs[0].iloc[[random_int]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = pd.DataFrame(columns=d.column_names)\n",
    "augmented['target'] = None\n",
    "\n",
    "for n_instance in range(1, d.len_train):\n",
    "    \n",
    "    instance = d.data_torch_train[n_instance]\n",
    "    \n",
    "    cfs = exp.generate_cfs(instance, f_fair=f_fair, total_cfs=3, output='df')\n",
    "    \n",
    "    random_int = random.randint(0, 2)\n",
    "    \n",
    "    augmented.loc[n_instance] = cfs[0].iloc[random_int].copy()\n",
    "    \n",
    "    if n_instance % 10 == 0:\n",
    "        \n",
    "        augmented.to_csv('augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-f62b390c4a38>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  original_data['target'] = target_original_data\n"
     ]
    }
   ],
   "source": [
    "d = Income()\n",
    "extra_data = pd.read_csv('output/income/augmented.csv')\n",
    "original_data = d.data_df_train.iloc[0:7990,:]\n",
    "target_original_data = d.target_df_train.iloc[0:7990]\n",
    "original_data['target'] = target_original_data\n",
    "augmented_dataset = pd.concat([original_data, extra_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss before training 0.7548929452896118\n",
      "Epoch: 0 -- train loss: 0.755 -- accuracy (test set): 0.197\n",
      "Epoch: 100 -- train loss: 0.323 -- accuracy (test set): 0.868\n",
      "Epoch: 200 -- train loss: 0.264 -- accuracy (test set): 0.897\n",
      "Epoch: 300 -- train loss: 0.251 -- accuracy (test set): 0.899\n",
      "Epoch: 400 -- train loss: 0.242 -- accuracy (test set): 0.901\n",
      "Epoch: 500 -- train loss: 0.237 -- accuracy (test set): 0.904\n",
      "Test loss after Training 0.24146902561187744\n",
      "The accuracy scrore on the test set: 0.904\n"
     ]
    }
   ],
   "source": [
    "d_augmented = Import(data_df = augmented_dataset, cont_indices=[6, 7])\n",
    "x_train = d_augmented.data_torch_train\n",
    "x_test = d_augmented.data_torch_test\n",
    "y_train = d_augmented.target_torch_train\n",
    "y_test = d_augmented.target_torch_test\n",
    "\n",
    "input_dim = len(x_train[0])\n",
    "hidden_dim = 100\n",
    "\n",
    "mlp_model = MLP(input_dim, hidden_dim)\n",
    "criterion = torch.nn.BCELoss() # BCE = binary cross entropy - our targets are binary \n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr = 0.001)\n",
    "\n",
    "### EVAL ###\n",
    "mlp_model.eval() # here sets the PyTorch module to evaluation mode. \n",
    "y_train_hat = mlp_model(x_train)\n",
    "before_train = criterion(y_train_hat.squeeze(), y_train)\n",
    "print('Test loss before training' , before_train.item())\n",
    "\n",
    "### TRAIN ###\n",
    "mlp_model.train() # here sets the PyTorch module to train mode. \n",
    "tot_epoch = 501\n",
    "for epoch in range(tot_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_train_hat = mlp_model(x_train)\n",
    "    # Compute Loss\n",
    "    loss = criterion(y_train_hat.squeeze(), y_train)\n",
    "    \n",
    "    if epoch%100==0:\n",
    "        y_test_hat = mlp_model(x_test)\n",
    "        print('Epoch: {} -- train loss: {} -- accuracy (test set): {}'.format(epoch, round(loss.item(), 3), mlp_model.accuracy(y_test_hat, y_test)))\n",
    "        y_test_hat = mlp_model(x_test)\n",
    "        \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "### EVAL ###\n",
    "mlp_model.eval()\n",
    "y_test_hat = mlp_model(x_test)\n",
    "after_train = criterion(y_test_hat.squeeze(), y_test) \n",
    "print('Test loss after Training' , after_train.item())\n",
    "\n",
    "print('The accuracy scrore on the test set:', mlp_model.accuracy(y_test_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp_model, \"mlp_income_augmented.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CF's again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Dice(d_augmented, mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_augmented.data_torch_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instances = len(y_test)\n",
    "all_instances = torch.zeros((n_instances, d_augmented.data_torch_test.shape[1]))\n",
    "all_cfs = torch.zeros((n_instances, 5, d_augmented.data_torch_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance 3995/3995\n",
      "percentage: 99.97%\n"
     ]
    }
   ],
   "source": [
    "for n_instance in range(d_augmented.len_test):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('instance ' + str(n_instance+1) + '/' + str(n_instances))\n",
    "    print('percentage: ' + str(round(n_instance*100/n_instances, 2)) + '%')\n",
    "    \n",
    "    instance = d_augmented.data_torch_test[n_instance]\n",
    "    \n",
    "    cfs = exp.generate_cfs(instance, total_cfs=5)\n",
    "    \n",
    "    all_cfs[n_instance] = cfs[0].clone()\n",
    "    \n",
    "    if n_instance % 10 == 0:\n",
    "        \n",
    "        torch.save(all_cfs, \"cfs_round2_income.pt\")\n",
    "        torch.save(all_instances, \"instances_round2_income.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2608, 0.3973],\n",
       "         [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2595, 0.4017],\n",
       "         [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2614, 0.3980],\n",
       "         [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2519, 0.3948],\n",
       "         [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2659, 0.3958]],\n",
       "\n",
       "        [[0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.4537, 0.3930],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4468, 0.3938],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4500, 0.4046],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4530, 0.3967],\n",
       "         [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.4495, 0.3959]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4212, 0.4966],\n",
       "         [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.4220, 0.5020],\n",
       "         [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4231, 0.5000],\n",
       "         [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4443, 0.4989],\n",
       "         [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4246, 0.5307]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>workclass</th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>School</td>\n",
       "      <td>Female</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>School</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Private</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Private</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>White</td>\n",
       "      <td>Private</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>School</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Private</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>Other</td>\n",
       "      <td>Government</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Private</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Other</td>\n",
       "      <td>Private</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Government</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Private</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       education  gender marital_status    occupation   race      workclass  \\\n",
       "0         School  Female        Widowed       Service  White  Self-Employed   \n",
       "1         School    Male         Single       Service  White        Private   \n",
       "2      Bachelors    Male         Single   Blue-Collar  White        Private   \n",
       "3        HS-grad    Male        Married  Professional  White        Private   \n",
       "4         School  Female         Single   Blue-Collar  White        Private   \n",
       "...          ...     ...            ...           ...    ...            ...   \n",
       "32556  Bachelors  Female         Single  White-Collar  Other     Government   \n",
       "32557  Bachelors    Male        Married  White-Collar  White        Private   \n",
       "32558  Bachelors    Male         Single   Blue-Collar  Other        Private   \n",
       "32559    HS-grad    Male        Married       Service  White     Government   \n",
       "32560  Bachelors    Male        Married  White-Collar  White        Private   \n",
       "\n",
       "       age  hours_per_week  \n",
       "0       62              66  \n",
       "1       18              25  \n",
       "2       25              50  \n",
       "3       33              40  \n",
       "4       36              40  \n",
       "...    ...             ...  \n",
       "32556   25              40  \n",
       "32557   32              45  \n",
       "32558   27              40  \n",
       "32559   59              40  \n",
       "32560   33              45  \n",
       "\n",
       "[32561 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Self-Employed', 'Private', 'Government', 'Other/Unknown'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.data_df['workclass'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Income()\n",
    "instances = torch.load(\"instances_round2_income.pt\")\n",
    "instances = d.torch_to_df(instances)\n",
    "cfs = torch.load(\"cfs_round2_income.pt\") # torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instances = cfs.shape[0]\n",
    "cfs_per_instance = cfs.shape[1]\n",
    "fair_cfs = 0\n",
    "\n",
    "for n_instance in range(n_instances):\n",
    "    instance = instances.iloc[n_instance]\n",
    "    cfs_i = d.torch_to_df(cfs[n_instance])\n",
    "    for n_cf in range(cfs_per_instance):\n",
    "        cf = cfs_i.iloc[n_cf]\n",
    "        if instance['gender'] == cf['gender'] and instance['race'] == cf['race']:\n",
    "            fair_cfs += 1\n",
    "            \n",
    "fair_ratio = fair_cfs / (n_instances * cfs_per_instance)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13541927409261578"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
